{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Módulo 6 - Machine Learning con PySpark\n",
    "\n",
    "## Dataset: Diamonds\n",
    "\n",
    "### **Objetivos:**\n",
    "\n",
    "1. **Carga de datos (10%)**\n",
    "   - Cargar el dataset `diamonds.csv` desde:\n",
    "     - `https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv`\n",
    "   - Definir un esquema explícito para los datos.\n",
    "\n",
    "2. **Pipeline de regresión (40%)**\n",
    "   - Predecir la variable `price`.\n",
    "   - Aplicar preprocesamiento con:\n",
    "     - `Imputer`\n",
    "     - `StringIndexer`\n",
    "     - `OneHotEncoder`\n",
    "     - `MinMaxScaler` o `StandardScaler`\n",
    "     - `VectorAssembler`\n",
    "   - Utilizar un modelo de regresión (ejemplo: `RandomForestRegressor`).\n",
    "\n",
    "3. **Pipeline de clasificación (40%)**\n",
    "   - Predecir la variable `cut` (multiclase).\n",
    "   - Aplicar preprocesamiento similar al de la regresión.\n",
    "   - Utilizar un modelo de clasificación (ejemplo: `MultiLayerPerceptronClassifier`).\n",
    "\n",
    "4. **GridSearch con CrossValidation (10%)**\n",
    "   - Aplicar `CrossValidator` con `GridSearch` para optimizar hiperparámetros en uno de los pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, when, round\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Descarga de datos\n",
    "import requests\n",
    "\n",
    "# PySpark ML - Preprocesamiento\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, MinMaxScaler, VectorAssembler\n",
    "\n",
    "# PySpark ML - Modelos\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, OneVsRest, LogisticRegression, MultilayerPerceptronClassifier\n",
    "\n",
    "# PySpark ML - Evaluación y optimización\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de Datos (10%)\n",
    "\n",
    "En esta sección se carga el dataset **\"diamonds.csv\"** desde la siguiente fuente:  \n",
    "🔗 [Dataset en GitHub](https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv)  \n",
    "\n",
    "### Pasos:\n",
    "1. **Descargar los datos** desde la URL y guardarlos en un archivo local.\n",
    "2. **Definir un esquema explícito** con los tipos de datos adecuados.\n",
    "3. **Cargar los datos en un DataFrame de PySpark** utilizando el esquema definido.\n",
    "4. **Mostrar los primeros registros y la estructura del DataFrame** para verificar la correcta importación.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- carat: float (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: float (nullable = true)\n",
      " |-- table: float (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: float (nullable = true)\n",
      " |-- y: float (nullable = true)\n",
      " |-- z: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"DiamondsML\").getOrCreate()\n",
    "\n",
    "# Descargar dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv\"\n",
    "csv_path = \"diamonds.csv\"\n",
    "\n",
    "with open(csv_path, 'wb') as file:\n",
    "    file.write(requests.get(url).content)\n",
    "\n",
    "# Definir esquema del dataset\n",
    "schema = StructType([\n",
    "    StructField(\"carat\", FloatType(), True),\n",
    "    StructField(\"cut\", StringType(), True),\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"clarity\", StringType(), True),\n",
    "    StructField(\"depth\", FloatType(), True),\n",
    "    StructField(\"table\", FloatType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"x\", FloatType(), True),\n",
    "    StructField(\"y\", FloatType(), True),\n",
    "    StructField(\"z\", FloatType(), True)\n",
    "])\n",
    "\n",
    "# Cargar datos con esquema\n",
    "df = spark.read.csv(csv_path, header=True, inferSchema=False, schema=schema)\n",
    "\n",
    "# Mostrar primeros registros y esquema\n",
    "df.show(5)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pipeline de Regresión (40%)  \n",
    "\n",
    "En esta sección se construye un **Pipeline de Regresión** para predecir el precio (`price`) de los diamantes utilizando modelos de Machine Learning en **PySpark MLlib**.  \n",
    "\n",
    "### Pasos:\n",
    "1. **Preprocesamiento de Datos**  \n",
    "   - Manejo de valores nulos con `Imputer`.  \n",
    "   - Codificación de variables categóricas con `StringIndexer` y `OneHotEncoder`.  \n",
    "   - Escalado de variables numéricas con `MinMaxScaler`.  \n",
    "   - Ensamblaje de todas las características en una sola columna (`features`).  \n",
    "\n",
    "2. **Modelado**  \n",
    "   - Se prueban dos modelos de regresión:  \n",
    "     - `RandomForestRegressor`   \n",
    "     - `GBTRegressor`   \n",
    "   - Se entrena cada modelo con los datos de entrenamiento.  \n",
    "\n",
    "3. **Evaluación de Modelos**  \n",
    "   - Se calculan métricas de rendimiento:  \n",
    "     - **R²** (coeficiente de determinación)  \n",
    "     - **RMSE** (error cuadrático medio raíz)  \n",
    "     - **MAE** (error absoluto medio)  \n",
    "     - **MSE** (error cuadrático medio)  \n",
    "   - Se compara el desempeño de ambos modelos y se selecciona el mejor.  \n",
    "\n",
    "4. **Guardado del Mejor Modelo**  \n",
    "   - Se almacena el modelo con mejor rendimiento para futuras predicciones.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|carat|cut|color|clarity|depth|table|price|  x|  y|  z|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|    0|  0|    0|      0|    0|    0|    0|  0|  0|  0|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contar valores nulos\n",
    "df.select([sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat', 'depth', 'table', 'x', 'y', 'z']\n",
      "['cut', 'color', 'clarity']\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+-----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|label|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+-----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|  326|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|  326|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|  327|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|  334|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|  335|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "numerical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType) and field.name != 'price']\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType)]\n",
    "label_col = 'price'\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "\n",
    "# Crear nueva columna \"label\" sin modificar \"price\"\n",
    "df = df.withColumn(\"label\", col(\"price\"))\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed', 'color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "# Indexar columnas categóricas sin sobrescribir las originales\n",
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + \"_indexed\", handleInvalid=\"keep\") for c in categorical_cols\n",
    "]\n",
    "\n",
    "categorical_cols_indexed = [c + \"_indexed\" for c in categorical_cols]\n",
    "\n",
    "print(categorical_cols_indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed_imputed', 'color_indexed_imputed', 'clarity_indexed_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos en categóricas indexadas con la moda\n",
    "imputer_categorical = Imputer(\n",
    "    inputCols=categorical_cols_indexed,\n",
    "    outputCols=[c + \"_imputed\" for c in categorical_cols_indexed],\n",
    "    strategy=\"mode\"\n",
    ")\n",
    "categorical_cols_imputed = [c + \"_imputed\" for c in categorical_cols_indexed]\n",
    "\n",
    "print(categorical_cols_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed_imputed_onehot', 'color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding para las categóricas imputadas\n",
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + \"_onehot\") for c in categorical_cols_imputed\n",
    "]\n",
    "categorical_cols_onehot = [c + \"_onehot\" for c in categorical_cols_imputed]\n",
    "\n",
    "print(categorical_cols_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat_imputed', 'depth_imputed', 'table_imputed', 'x_imputed', 'y_imputed', 'z_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos en numéricas con la mediana\n",
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + \"_imputed\" for c in numerical_cols],\n",
    "    strategy=\"median\"\n",
    ")\n",
    "numerical_cols_imputed = [c + \"_imputed\" for c in numerical_cols]\n",
    "\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar numéricas con MinMaxScaler\n",
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol=\"numeric_features\"\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"numeric_features\",\n",
    "    outputCol=\"numeric_features_scaled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamblar todas las características\n",
    "all_features = [\"numeric_features_scaled\"] + categorical_cols_onehot\n",
    "assembler_all = VectorAssembler(inputCols=all_features, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de regresión\n",
    "regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=\"price\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_regressor = GBTRegressor(featuresCol=\"features\", labelCol=\"price\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear pipeline con TODAS las etapas en orden\n",
    "pipeline_rf = Pipeline(stages=[\n",
    "    *indexers_features,   \n",
    "    imputer_categorical,  \n",
    "    *encoders_onehot,     \n",
    "    imputer_numerical,    \n",
    "    assembler_numerical,  \n",
    "    scaler,               \n",
    "    assembler_all,        \n",
    "    regressor   # Modelo RF\n",
    "])\n",
    "\n",
    "pipeline_gbt = Pipeline(stages=[\n",
    "    *indexers_features,   \n",
    "    imputer_categorical,  \n",
    "    *encoders_onehot,     \n",
    "    imputer_numerical,    \n",
    "    assembler_numerical,  \n",
    "    scaler,               \n",
    "    assembler_all,        \n",
    "    gbt_regressor   # Modelo GBT\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento (80%) y prueba (20%)\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "pipeline_model_rf = pipeline_rf.fit(df_train)\n",
    "pipeline_model_gbt = pipeline_gbt.fit(df_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "df_pred_rf = pipeline_model_rf.transform(df_test)\n",
    "df_pred_gbt = pipeline_model_gbt.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Comparación de Modelos de Regresión**\n",
      "RandomForestRegressor - R²: 0.9070 | RMSE: 1229.87 | MAE: 684.11 | MSE: 1512592.39\n",
      "GBTRegressor - R²: 0.9462 | RMSE: 935.20 | MAE: 501.64 | MSE: 874589.89\n",
      "\n",
      "Mejor modelo seleccionado: GBTRegressor\n"
     ]
    }
   ],
   "source": [
    "# Evaluadores para las métricas de regresión\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_mse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "\n",
    "# Calcular métricas\n",
    "r2_rf = evaluator_r2.evaluate(df_pred_rf)\n",
    "r2_gbt = evaluator_r2.evaluate(df_pred_gbt)\n",
    "rmse_rf = evaluator_rmse.evaluate(df_pred_rf)\n",
    "rmse_gbt = evaluator_rmse.evaluate(df_pred_gbt)\n",
    "mae_rf = evaluator_mae.evaluate(df_pred_rf)\n",
    "mae_gbt = evaluator_mae.evaluate(df_pred_gbt)\n",
    "mse_rf = evaluator_mse.evaluate(df_pred_rf)\n",
    "mse_gbt = evaluator_mse.evaluate(df_pred_gbt)\n",
    "\n",
    "\n",
    "print(\"\\n**Comparación de Modelos de Regresión**\")\n",
    "print(f\"RandomForestRegressor - R²: {r2_rf:.4f} | RMSE: {rmse_rf:.2f} | MAE: {mae_rf:.2f} | MSE: {mse_rf:.2f}\")\n",
    "print(f\"GBTRegressor - R²: {r2_gbt:.4f} | RMSE: {rmse_gbt:.2f} | MAE: {mae_gbt:.2f} | MSE: {mse_gbt:.2f}\")\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_pipeline = pipeline_model_gbt if r2_gbt > r2_rf else pipeline_model_rf\n",
    "print(f\"\\nMejor modelo seleccionado: {'GBTRegressor' if r2_gbt > r2_rf else 'RandomForestRegressor'}\")\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "best_pipeline.write().overwrite().save(\"models/best_diamond_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GridSearch con CrossValidation (10%)  \n",
    "\n",
    "En esta sección se optimiza el **modelo de regresión** utilizando **Validación Cruzada** y **Búsqueda en Cuadrícula (GridSearch)**.  \n",
    "\n",
    "### Pasos:\n",
    "1. **Definir hiperparámetros a ajustar**  \n",
    "   - `numTrees`: número de árboles en el bosque aleatorio (`[10, 20, 30]`).  \n",
    "   - `maxDepth`: profundidad máxima de cada árbol (`[5, 10, 15]`).  \n",
    "\n",
    "2. **Aplicar Validación Cruzada**  \n",
    "   - Se usa **3-Fold Cross Validation**.  \n",
    "   - Se mide el rendimiento con **R²**.  \n",
    "   - Se entrena el **GBTRegressor** con todas las combinaciones de hiperparámetros.  \n",
    "\n",
    "3. **Evaluación del Mejor Modelo**  \n",
    "   - Se selecciona la mejor combinación de hiperparámetros.  \n",
    "   - Se calculan las métricas:  \n",
    "     - **R²**  \n",
    "     - **RMSE**  \n",
    "     - **MAE**  \n",
    "     - **MSE**  \n",
    "\n",
    "4. **Guardar el Mejor Modelo**  \n",
    "   - Se almacena el modelo optimizado en `models/diamond_regression_best`.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Mejor Modelo de Regresión (GridSearch + CrossValidation)**\n",
      "R²: 0.9462  (Cuanto más cercano a 1, mejor)\n",
      "RMSE: 935.20  (Error cuadrático medio raíz, cuanto menor mejor)\n",
      "MAE: 501.64  (Error absoluto medio, cuanto menor mejor)\n",
      "MSE: 874589.89  (Error cuadrático medio, cuanto menor mejor)\n",
      "\n",
      "Mejor modelo de regresión guardado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Definir la cuadrícula de hiperparámetros\n",
    "paramGrid_regression = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(regressor.numTrees, [10, 20, 30])  # Número de árboles\n",
    "    .addGrid(regressor.maxDepth, [5, 10, 15])  # Profundidad máxima\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Configurar CrossValidator\n",
    "crossval_regression = CrossValidator(\n",
    "    estimator=pipeline_gbt,  # Usamos el pipeline de regresión\n",
    "    estimatorParamMaps=paramGrid_regression,  # Hiperparámetros\n",
    "    evaluator=evaluator_r2,  # Evaluamos con R²\n",
    "    numFolds=3,  # 3-Fold Cross Validation\n",
    "    parallelism=4,  # Procesamiento paralelo\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo optimizado\n",
    "cv_model_regression = crossval_regression.fit(df_train)\n",
    "\n",
    "# Hacer predicciones con el mejor modelo\n",
    "df_pred_cv_regression = cv_model_regression.transform(df_test)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "r2_cv = evaluator_r2.evaluate(df_pred_cv_regression)\n",
    "rmse_cv = evaluator_rmse.evaluate(df_pred_cv_regression)\n",
    "mae_cv = evaluator_mae.evaluate(df_pred_cv_regression)\n",
    "mse_cv = evaluator_mse.evaluate(df_pred_cv_regression)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n**Evaluación del Mejor Modelo de Regresión (GridSearch + CrossValidation)**\")\n",
    "print(f\"R²: {r2_cv:.4f}  (Cuanto más cercano a 1, mejor)\")\n",
    "print(f\"RMSE: {rmse_cv:.2f}  (Error cuadrático medio raíz, cuanto menor mejor)\")\n",
    "print(f\"MAE: {mae_cv:.2f}  (Error absoluto medio, cuanto menor mejor)\")\n",
    "print(f\"MSE: {mse_cv:.2f}  (Error cuadrático medio, cuanto menor mejor)\")\n",
    "\n",
    "# Guardar el modelo optimizado\n",
    "cv_model_regression.bestModel.write().overwrite().save(\"models/diamond_regression_best\")\n",
    "\n",
    "print(\"\\nMejor modelo de regresión guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Mejor Modelo de Regresión Cargado**\n",
      "R²: 0.9462  (Cuanto más cercano a 1, mejor)\n",
      "RMSE: 935.20  (Error cuadrático medio raíz, cuanto menor mejor)\n",
      "MAE: 501.64  (Error absoluto medio, cuanto menor mejor)\n",
      "MSE: 874589.89  (Error cuadrático medio, cuanto menor mejor)\n",
      "+--------------------+-----+------------------+\n",
      "|            features|label|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|(23,[1,2,3,4,5,6,...|  367| 559.1611988232905|\n",
      "|(23,[1,2,3,4,5,7,...|  367|498.98727992519423|\n",
      "|(23,[1,2,3,4,5,7,...|  367| 509.6352558537926|\n",
      "|(23,[0,1,2,3,4,5,...|  386| 617.6673701952654|\n",
      "|(23,[0,1,2,3,4,5,...|  386| 519.3629843189983|\n",
      "|(23,[0,1,2,3,4,5,...|  404| 519.3629843189983|\n",
      "|(23,[0,1,2,3,4,5,...|  452| 733.5297114669011|\n",
      "|(23,[0,1,2,3,4,5,...|  439| 650.9265566085334|\n",
      "|(23,[0,1,2,3,4,5,...|  376| 643.3707221153938|\n",
      "|(23,[0,1,2,3,4,5,...|  442|509.21243595786325|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el mejor modelo de regresión\n",
    "best_regression_model = PipelineModel.load(\"models/diamond_regression_best\")\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "df_pred_best_regression = best_regression_model.transform(df_test)\n",
    "\n",
    "# Evaluar el modelo cargado\n",
    "r2_best = evaluator_r2.evaluate(df_pred_best_regression)\n",
    "rmse_best = evaluator_rmse.evaluate(df_pred_best_regression)\n",
    "mae_best = evaluator_mae.evaluate(df_pred_best_regression)\n",
    "mse_best = evaluator_mse.evaluate(df_pred_best_regression)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n**Evaluación del Mejor Modelo de Regresión Cargado**\")\n",
    "print(f\"R²: {r2_best:.4f}  (Cuanto más cercano a 1, mejor)\")\n",
    "print(f\"RMSE: {rmse_best:.2f}  (Error cuadrático medio raíz, cuanto menor mejor)\")\n",
    "print(f\"MAE: {mae_best:.2f}  (Error absoluto medio, cuanto menor mejor)\")\n",
    "print(f\"MSE: {mse_best:.2f}  (Error cuadrático medio, cuanto menor mejor)\")\n",
    "\n",
    "# Mostrar algunas predicciones\n",
    "df_pred_best_regression.select(\"features\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|Real Price|Predicted Price|\n",
      "+----------+---------------+\n",
      "|       367|         559.16|\n",
      "|       367|         498.99|\n",
      "|       367|         509.64|\n",
      "|       386|         617.67|\n",
      "|       386|         519.36|\n",
      "|       404|         519.36|\n",
      "|       452|         733.53|\n",
      "|       439|         650.93|\n",
      "|       376|         643.37|\n",
      "|       442|         509.21|\n",
      "|       357|          494.9|\n",
      "|       458|         728.42|\n",
      "|       462|         617.18|\n",
      "|       395|         531.13|\n",
      "|       548|         559.16|\n",
      "+----------+---------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las columnas de interés y redondear la predicción para mejor visualización\n",
    "df_comparison_regression = df_pred_best_regression.select(\n",
    "    col(\"label\").alias(\"Real Price\"), \n",
    "    round(col(\"prediction\"), 2).alias(\"Predicted Price\")\n",
    ")\n",
    "\n",
    "# Mostrar los primeros 15 valores reales vs. predicciones\n",
    "df_comparison_regression.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pipeline de Clasificación (40%)  \n",
    "\n",
    "En esta sección se entrena un modelo de **clasificación multiclase** para predecir la variable `cut` del diamante.  \n",
    "\n",
    "## Pasos:  \n",
    "\n",
    "### **1 Preprocesamiento de Datos**  \n",
    "- **Categóricas**:  \n",
    "  - Se convierten a valores numéricos con `StringIndexer`.  \n",
    "  - Se imputan valores nulos con `Imputer`.  \n",
    "  - Se aplica `OneHotEncoder`.  \n",
    "- **Numéricas**:  \n",
    "  - Se imputan valores nulos con `Imputer`.  \n",
    "  - Se normalizan con `MinMaxScaler`.  \n",
    "- **VectorAssembler** para combinar todas las características en una única columna `features`.  \n",
    "\n",
    "### **2️ Modelos de Clasificación**  \n",
    "- **RandomForestClassifier**  \n",
    "- **OneVsRest (Logistic Regression)**  \n",
    "\n",
    "### **3️ Creación de Pipelines**  \n",
    "- Se crean **dos pipelines de clasificación**, uno con **RandomForest** y otro con **OneVsRest**.  \n",
    "\n",
    "### **4️ Entrenamiento y Evaluación**  \n",
    "- Se entrenan ambos modelos en los datos de entrenamiento.  \n",
    "- Se hacen predicciones en el conjunto de prueba.  \n",
    "- Se calculan las métricas de evaluación:  \n",
    "  - **Accuracy**  \n",
    "  - **F1-Score**  \n",
    "  - **Precision**  \n",
    "  - **Recall**  \n",
    "\n",
    "### **5️ Selección del Mejor Modelo**  \n",
    "- Se compara el rendimiento de ambos modelos.  \n",
    "- Se guarda el modelo con **mejor rendimiento** en `models/best_diamond_classification`.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame para clasificación\n",
    "df_classification = df.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna \"label\" si ya existe en df_classification\n",
    "if \"label\" in df_classification.columns:\n",
    "    df_classification = df_classification.drop(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categóricas: ['color', 'clarity']\n",
      "Numéricas: ['carat', 'depth', 'table', 'x', 'y', 'z', 'price']\n"
     ]
    }
   ],
   "source": [
    "# Variables categóricas (sin incluir la label 'cut')\n",
    "categorical_cols_classification = [col for col in categorical_cols if col != \"cut\"]\n",
    "\n",
    "# Variables numéricas (agregando 'price')\n",
    "numerical_cols_classification = numerical_cols + [\"price\"]\n",
    "\n",
    "# Definir la columna a predecir\n",
    "label_col_classification = \"cut\"\n",
    "\n",
    "print(\"Categóricas:\", categorical_cols_classification)\n",
    "print(\"Numéricas:\", numerical_cols_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexar la variable objetivo (cut) convirtiéndola en label\n",
    "indexer_label = StringIndexer(inputCol=\"cut\", outputCol=\"label\", handleInvalid=\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas indexadas: ['color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "# Indexar las features categóricas\n",
    "indexers_features_classification = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + \"_indexed\", handleInvalid=\"keep\") \n",
    "    for c in categorical_cols_classification\n",
    "]\n",
    "\n",
    "# Lista de columnas indexadas\n",
    "categorical_cols_indexed_classification = [c + \"_indexed\" for c in categorical_cols_classification]\n",
    "\n",
    "print(\"Columnas categóricas indexadas:\", categorical_cols_indexed_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas imputadas: ['color_indexed_imputed', 'clarity_indexed_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputar con la moda las columnas categóricas indexadas\n",
    "imputer_categorical_classification = Imputer(\n",
    "    inputCols=categorical_cols_indexed_classification,\n",
    "    outputCols=[c + \"_imputed\" for c in categorical_cols_indexed_classification],\n",
    "    strategy=\"mode\"\n",
    ")\n",
    "\n",
    "# Lista de columnas categóricas indexadas e imputadas\n",
    "categorical_cols_imputed_classification = [c + \"_imputed\" for c in categorical_cols_indexed_classification]\n",
    "\n",
    "print(\"Columnas categóricas imputadas:\", categorical_cols_imputed_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas codificadas con One-Hot Encoding: ['color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "# Aplicar One-Hot Encoding a las categóricas indexadas e imputadas\n",
    "encoders_onehot_classification = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + \"_onehot\") \n",
    "    for c in categorical_cols_imputed_classification\n",
    "]\n",
    "\n",
    "# Lista de columnas categóricas después del One-Hot Encoding\n",
    "categorical_cols_onehot_classification = [c + \"_onehot\" for c in categorical_cols_imputed_classification]\n",
    "\n",
    "print(\"Columnas categóricas codificadas con One-Hot Encoding:\", categorical_cols_onehot_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas imputadas: ['carat_imputed', 'depth_imputed', 'table_imputed', 'x_imputed', 'y_imputed', 'z_imputed', 'price_imputed']\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos en numéricas con la mediana\n",
    "imputer_numerical_classification = Imputer(\n",
    "    inputCols=numerical_cols_classification,\n",
    "    outputCols=[c + \"_imputed\" for c in numerical_cols_classification],\n",
    "    strategy=\"median\"\n",
    ")\n",
    "\n",
    "# Lista de columnas numéricas imputadas\n",
    "numerical_cols_imputed_classification = [c + \"_imputed\" for c in numerical_cols_classification]\n",
    "\n",
    "print(\"Columnas numéricas imputadas:\", numerical_cols_imputed_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización lista: Se escalarán las variables numéricas en un rango de 0 a 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensamblar las columnas numéricas imputadas en un solo vector antes de escalar\n",
    "assembler_numerical_classification = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed_classification,\n",
    "    outputCol=\"numeric_features\"\n",
    ")\n",
    "\n",
    "# Aplicar MinMaxScaler a las variables numéricas\n",
    "scaler_classification = MinMaxScaler(\n",
    "    inputCol=\"numeric_features\",\n",
    "    outputCol=\"numeric_features_scaled\"\n",
    ")\n",
    "\n",
    "print(\"Normalización lista: Se escalarán las variables numéricas en un rango de 0 a 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamblaje final: Todas las variables estarán listas para el modelo de clasificación.\n"
     ]
    }
   ],
   "source": [
    "# Lista de todas las características finales\n",
    "all_features_classification = [\"numeric_features_scaled\"] + categorical_cols_onehot_classification\n",
    "\n",
    "# Ensamblar todas las características en una única columna \"features\"\n",
    "assembler_all_classification = VectorAssembler(\n",
    "    inputCols=all_features_classification,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "print(\"Ensamblaje final: Todas las variables estarán listas para el modelo de clasificación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de clasificación seleccionado: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de clasificación\n",
    "classifier = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Modelo de clasificación seleccionado: RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo base para OneVsRest (Logistic Regression)\n",
    "base_classifier = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Configurar OneVsRest\n",
    "one_vs_rest_classifier = OneVsRest(classifier=base_classifier, labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipelines de clasificación creados con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Crear el pipeline con RandomForestClassifier\n",
    "pipeline_classification_rf = Pipeline(stages=[\n",
    "    indexer_label,                # Indexar la variable objetivo\n",
    "    *indexers_features_classification,  # Indexar categóricas\n",
    "    imputer_categorical_classification,  # Imputar categóricas\n",
    "    *encoders_onehot_classification,  # OneHotEncoder\n",
    "    imputer_numerical_classification,  # Imputar numéricas\n",
    "    assembler_numerical_classification,  # Ensamblar numéricas\n",
    "    scaler_classification,  # Escalar numéricas\n",
    "    assembler_all_classification,  # Ensamblar todas las features\n",
    "    classifier  # Modelo de clasificación\n",
    "])\n",
    "\n",
    "\n",
    "# Crear el pipeline con OneVsRest\n",
    "pipeline_classification_ovr = Pipeline(stages=[\n",
    "    indexer_label,                \n",
    "    *indexers_features_classification,  \n",
    "    imputer_categorical_classification,  \n",
    "    *encoders_onehot_classification,  \n",
    "    imputer_numerical_classification,  \n",
    "    assembler_numerical_classification,  \n",
    "    scaler_classification,  \n",
    "    assembler_all_classification,  \n",
    "    one_vs_rest_classifier  \n",
    "])\n",
    "\n",
    "print(\"Pipelines de clasificación creados con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos divididos: 43083 en entrenamiento, 10857 en prueba.\n"
     ]
    }
   ],
   "source": [
    "# Particionar los datos\n",
    "df_train_classification, df_test_classification = df_classification.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Datos divididos: {df_train_classification.count()} en entrenamiento, {df_test_classification.count()} en prueba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos de clasificación entrenados con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el pipeline de clasificación\n",
    "pipeline_model_classification_rf = pipeline_classification_rf.fit(df_train_classification)\n",
    "pipeline_model_classification_ovr = pipeline_classification_ovr.fit(df_train_classification)\n",
    "\n",
    "print(\"Modelos de clasificación entrenados con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "|    cut|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|  Ideal|  0.0|       0.0|\n",
      "|Premium|  1.0|       2.0|\n",
      "|Premium|  1.0|       2.0|\n",
      "|Premium|  1.0|       2.0|\n",
      "|Premium|  1.0|       2.0|\n",
      "|Premium|  1.0|       2.0|\n",
      "|   Good|  3.0|       2.0|\n",
      "|   Good|  3.0|       2.0|\n",
      "|   Good|  3.0|       2.0|\n",
      "|   Good|  3.0|       0.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-----+----------+\n",
      "|    cut|label|prediction|\n",
      "+-------+-----+----------+\n",
      "|  Ideal|  0.0|       0.0|\n",
      "|Premium|  1.0|       1.0|\n",
      "|Premium|  1.0|       1.0|\n",
      "|Premium|  1.0|       1.0|\n",
      "|Premium|  1.0|       1.0|\n",
      "|Premium|  1.0|       1.0|\n",
      "|   Good|  3.0|       1.0|\n",
      "|   Good|  3.0|       1.0|\n",
      "|   Good|  3.0|       2.0|\n",
      "|   Good|  3.0|       0.0|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en los datos de prueba\n",
    "df_pred_classification_rf = pipeline_model_classification_rf.transform(df_test_classification)\n",
    "df_pred_classification_ovr = pipeline_model_classification_ovr.transform(df_test_classification)\n",
    "\n",
    "# Mostrar algunas predicciones\n",
    "df_pred_classification_rf.select(\"cut\", \"label\", \"prediction\").show(10)\n",
    "df_pred_classification_ovr.select(\"cut\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Comparación de Modelos de Clasificación**\n",
      "RandomForestClassifier - Accuracy: 0.6774 F1-Score: 0.6354 | Precision: 0.6623 | Recall: 0.6774\n",
      "GBTClassifier - Accuracy: 0.6161 F1-Score: 0.5639 | Precision: 0.5913 | Recall: 0.6161\n",
      "\n",
      "Mejor modelo de clasificación: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Definir evaluadores\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Evaluar métricas\n",
    "accuracy_rf = evaluator_accuracy.evaluate(df_pred_classification_rf)\n",
    "accuracy_ovr = evaluator_accuracy.evaluate(df_pred_classification_ovr)\n",
    "f1_rf = evaluator_f1.evaluate(df_pred_classification_rf)\n",
    "f1_ovr = evaluator_f1.evaluate(df_pred_classification_ovr)\n",
    "precision_rf = evaluator_precision.evaluate(df_pred_classification_rf)\n",
    "precision_ovr = evaluator_precision.evaluate(df_pred_classification_ovr)\n",
    "recall_rf = evaluator_recall.evaluate(df_pred_classification_rf)\n",
    "recall_ovr = evaluator_recall.evaluate(df_pred_classification_ovr)\n",
    "\n",
    "print(\"\\n**Comparación de Modelos de Clasificación**\")\n",
    "print(f\"RandomForestClassifier - Accuracy: {accuracy_rf:.4f} F1-Score: {f1_rf:.4f} | Precision: {precision_rf:.4f} | Recall: {recall_rf:.4f}\")\n",
    "print(f\"GBTClassifier - Accuracy: {accuracy_ovr:.4f} F1-Score: {f1_ovr:.4f} | Precision: {precision_ovr:.4f} | Recall: {recall_ovr:.4f}\")\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_pipeline_classification = pipeline_model_classification_ovr if accuracy_ovr > accuracy_rf else pipeline_model_classification_rf\n",
    "print(f\"\\nMejor modelo de clasificación: {'OneVsRest' if accuracy_ovr > accuracy_rf else 'RandomForestClassifier'}\")\n",
    "\n",
    "# Guardar el mejor modelo de clasificación\n",
    "best_pipeline_classification.write().overwrite().save(\"models/best_diamond_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Mejor Modelo de Clasificación (GridSearch + CrossValidation)**\n",
      "Accuracy: 0.7267 (Porcentaje de predicciones correctas)\n",
      "F1-Score: 0.7090 (Balance entre precisión y recall)\n",
      "Precision: 0.7131 (Exactitud de las predicciones)\n",
      "Recall: 0.7267 (Capacidad de detectar correctamente cada clase)\n",
      "\n",
      "Mejor modelo de clasificación guardado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Definir la cuadrícula de hiperparámetros para clasificación\n",
    "paramGrid_classification = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(classifier.numTrees, [10, 20, 30])  # Número de árboles\n",
    "    .addGrid(classifier.maxDepth, [5, 10, 15])  # Profundidad máxima\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Configurar CrossValidator\n",
    "crossval_classification = CrossValidator(\n",
    "    estimator=pipeline_classification_rf,  # Usamos el pipeline de clasificación\n",
    "    estimatorParamMaps=paramGrid_classification,  # Hiperparámetros\n",
    "    evaluator=evaluator_f1,  # Evaluamos con F1-Score\n",
    "    numFolds=3,  # 3-Fold Cross Validation\n",
    "    parallelism=4,  # Procesamiento paralelo\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo optimizado\n",
    "cv_model_classification = crossval_classification.fit(df_train_classification)\n",
    "\n",
    "# Hacer predicciones con el mejor modelo\n",
    "df_pred_cv_classification = cv_model_classification.transform(df_test_classification)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "accuracy_cv = evaluator_accuracy.evaluate(df_pred_cv_classification)\n",
    "f1_cv = evaluator_f1.evaluate(df_pred_cv_classification)\n",
    "precision_cv = evaluator_precision.evaluate(df_pred_cv_classification)\n",
    "recall_cv = evaluator_recall.evaluate(df_pred_cv_classification)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n**Evaluación del Mejor Modelo de Clasificación (GridSearch + CrossValidation)**\")\n",
    "print(f\"Accuracy: {accuracy_cv:.4f} (Porcentaje de predicciones correctas)\")\n",
    "print(f\"F1-Score: {f1_cv:.4f} (Balance entre precisión y recall)\")\n",
    "print(f\"Precision: {precision_cv:.4f} (Exactitud de las predicciones)\")\n",
    "print(f\"Recall: {recall_cv:.4f} (Capacidad de detectar correctamente cada clase)\")\n",
    "\n",
    "# Guardar el modelo optimizado\n",
    "cv_model_classification.bestModel.write().overwrite().save(\"models/diamond_classification_best\")\n",
    "\n",
    "print(\"\\nMejor modelo de clasificación guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimización con Validación Cruzada (GridSearch + CrossValidation)  \n",
    "\n",
    "Para mejorar el modelo de clasificación, se implementa **validación cruzada con GridSearch** para optimizar hiperparámetros.  \n",
    "\n",
    "## Pasos:  \n",
    "\n",
    "### **1️ Definir la cuadrícula de hiperparámetros**  \n",
    "Se prueban diferentes combinaciones de los siguientes parámetros:  \n",
    "- **`numTrees`** (número de árboles): `[10, 20, 30]`  \n",
    "- **`maxDepth`** (profundidad del árbol): `[5, 10, 15]`  \n",
    "\n",
    "### **2️ Configurar CrossValidator**  \n",
    "- Se utiliza **validación cruzada de 3 particiones** (`numFolds=3`).  \n",
    "- Se evalúa el modelo con la métrica **F1-Score**.  \n",
    "- Se habilita **procesamiento paralelo** (`parallelism=4`) para mayor velocidad.  \n",
    "\n",
    "### **3️ Entrenamiento y Selección del Mejor Modelo**  \n",
    "- Se entrena el modelo optimizado.  \n",
    "- Se selecciona el conjunto de hiperparámetros que maximiza el rendimiento.  \n",
    "\n",
    "### **4️ Evaluación del Mejor Modelo**  \n",
    "Se evalúan las métricas en el conjunto de prueba:  \n",
    "**Accuracy** (porcentaje de predicciones correctas).  \n",
    "**F1-Score** (balance entre precisión y recall).  \n",
    "**Precision** (exactitud de las predicciones).  \n",
    "**Recall** (capacidad de detectar correctamente cada clase).  \n",
    "\n",
    "### **5️ Guardar el Mejor Modelo**  \n",
    "El modelo optimizado se guarda en **`models/diamond_classification_best`** para futuras predicciones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Mejor Modelo de Clasificación Cargado**\n",
      "Accuracy: 0.7267 (Porcentaje de predicciones correctas)\n",
      "F1-Score: 0.7090 (Balance entre precisión y recall)\n",
      "Precision: 0.7131 (Exactitud de las predicciones)\n",
      "Recall: 0.7267 (Capacidad de detectar correctamente cada clase)\n",
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(20,[1,2,3,4,5,6,...|  0.0|       0.0|\n",
      "|(20,[1,2,3,4,5,6,...|  1.0|       2.0|\n",
      "|(20,[1,2,3,4,5,6,...|  1.0|       1.0|\n",
      "|(20,[0,1,2,3,4,5,...|  1.0|       1.0|\n",
      "|(20,[0,1,2,3,4,5,...|  1.0|       2.0|\n",
      "|(20,[0,1,2,3,4,5,...|  1.0|       2.0|\n",
      "|(20,[0,1,2,3,4,5,...|  3.0|       2.0|\n",
      "|(20,[0,1,2,3,4,5,...|  3.0|       2.0|\n",
      "|(20,[0,1,2,3,4,5,...|  3.0|       2.0|\n",
      "|(20,[0,1,2,3,4,5,...|  3.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el mejor modelo de clasificación\n",
    "best_classification_model = PipelineModel.load(\"models/diamond_classification_best\")\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "df_pred_best_classification = best_classification_model.transform(df_test_classification)\n",
    "\n",
    "# Evaluar el modelo cargado\n",
    "accuracy_best = evaluator_accuracy.evaluate(df_pred_best_classification)\n",
    "f1_best = evaluator_f1.evaluate(df_pred_best_classification)\n",
    "precision_best = evaluator_precision.evaluate(df_pred_best_classification)\n",
    "recall_best = evaluator_recall.evaluate(df_pred_best_classification)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n**Evaluación del Mejor Modelo de Clasificación Cargado**\")\n",
    "print(f\"Accuracy: {accuracy_best:.4f} (Porcentaje de predicciones correctas)\")\n",
    "print(f\"F1-Score: {f1_best:.4f} (Balance entre precisión y recall)\")\n",
    "print(f\"Precision: {precision_best:.4f} (Exactitud de las predicciones)\")\n",
    "print(f\"Recall: {recall_best:.4f} (Capacidad de detectar correctamente cada clase)\")\n",
    "\n",
    "# Mostrar algunas predicciones\n",
    "df_pred_best_classification.select(\"features\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|    cut|Predicted Cut|\n",
      "+-------+-------------+\n",
      "|  Ideal|        Ideal|\n",
      "|Premium|    Very Good|\n",
      "|Premium|      Premium|\n",
      "|Premium|      Premium|\n",
      "|Premium|    Very Good|\n",
      "|Premium|    Very Good|\n",
      "|   Good|    Very Good|\n",
      "|   Good|    Very Good|\n",
      "|   Good|    Very Good|\n",
      "|   Good|        Ideal|\n",
      "|   Good|         Good|\n",
      "|   Good|    Very Good|\n",
      "|   Good|    Very Good|\n",
      "|   Good|    Very Good|\n",
      "|  Ideal|        Ideal|\n",
      "+-------+-------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener los labels originales para decodificar la predicción\n",
    "labels_cut = indexer_label.fit(df_classification).labels  # Lista de nombres de los cortes\n",
    "\n",
    "# Crear una función para mapear los índices a nombres originales\n",
    "def decode_cut(index):\n",
    "    return labels_cut[int(index)]\n",
    "\n",
    "# Usar una UDF (User Defined Function) para aplicar la conversión en Spark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "decode_udf = udf(decode_cut, StringType())\n",
    "\n",
    "# Aplicar la conversión y comparar\n",
    "df_comparison_classification = df_pred_best_classification.withColumn(\n",
    "    \"Predicted Cut\", decode_udf(col(\"prediction\"))\n",
    ").select(\"cut\", \"Predicted Cut\")\n",
    "\n",
    "# Mostrar los primeros 15 valores reales vs. predicciones\n",
    "df_comparison_classification.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Suplemento: Modelo de Red Neuronal (MultilayerPerceptronClassifier)**\n",
    "\n",
    "Para complementar el análisis, se implementa un modelo de **Red Neuronal Artificial (MLP)** utilizando `MultilayerPerceptronClassifier` de **PySpark MLlib**.  \n",
    "\n",
    "### **Objetivo**\n",
    "Predecir la categoría de `cut` de un diamante a partir de sus características utilizando una red neuronal multicapa.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Pasos del Modelo MLP**\n",
    "#### 1️ **Carga de Datos**  \n",
    "   - Se usa el mismo dataset `diamonds.csv`.  \n",
    "   - Se crea una copia para el modelo MLP.  \n",
    "\n",
    "#### 2️ **Preprocesamiento de Datos**  \n",
    "   - **Indexación**: Se convierten las variables categóricas (`cut`, `color`, `clarity`) en valores numéricos con `StringIndexer`.  \n",
    "   - **Imputación de valores nulos**:  \n",
    "     - Categóricas: Se reemplazan con la **moda** (`Imputer` con `strategy=\"mode\"`).  \n",
    "     - Numéricas: Se reemplazan con la **mediana** (`Imputer` con `strategy=\"median\"`).  \n",
    "   - **Codificación One-Hot**: Se aplica `OneHotEncoder` a las variables categóricas indexadas (`color`, `clarity`).  \n",
    "   - **Vectorización**:  \n",
    "     - Se ensamblan todas las características en una columna `features` con `VectorAssembler`.  \n",
    "     - Se normaliza con `MinMaxScaler` para mejorar la estabilidad del entrenamiento.  \n",
    "\n",
    "#### 3️ **Definición de la Red Neuronal**  \n",
    "   - Se determina automáticamente el **número de características** de entrada (`features`).  \n",
    "   - Se establece el **número de clases** en la salida (`cut`).  \n",
    "   - Se define la arquitectura de la red con **dos capas ocultas**:  \n",
    "     ```python\n",
    "     layers = [num_features, 64, 32, num_classes]\n",
    "     ```\n",
    "     Donde:  \n",
    "     - `num_features`: Número total de características de entrada.  \n",
    "     - `64, 32`: Capas ocultas con 64 y 32 neuronas respectivamente.  \n",
    "     - `num_classes`: Número de categorías en `cut` (salida).  \n",
    "\n",
    "#### 4️ **Entrenamiento y Evaluación**  \n",
    "   - Se entrena el modelo con `MultilayerPerceptronClassifier`.  \n",
    "   - Se dividen los datos en **80% entrenamiento y 20% prueba**.  \n",
    "   - Se mide el rendimiento con:  \n",
    "     - `Accuracy` (Exactitud).  \n",
    "     - `F1-Score` (Balance entre precisión y recall).  \n",
    "     - `Precision` (Exactitud de las predicciones).  \n",
    "     - `Recall` (Capacidad de detectar correctamente cada clase).  \n",
    "\n",
    "#### 5️ **Guardado del Modelo**  \n",
    "   - Se almacena el modelo en `models/best_mlp_classification` para futuras predicciones.  \n",
    "\n",
    "---\n",
    "\n",
    "### 6 **Arquitectura del Modelo**\n",
    "El modelo se construye con la siguiente arquitectura:\n",
    "\n",
    "| Capa           | Número de Neuronas |\n",
    "|---------------|--------------------|\n",
    "| **Entrada**   | `num_features` (20 aprox.) |\n",
    "| **Capa Oculta 1** | 64 |\n",
    "| **Capa Oculta 2** | 32 |\n",
    "| **Salida**    | `num_classes` (5) |\n",
    "\n",
    "Este diseño permite capturar relaciones complejas entre las características y mejorar la predicción de la variable `cut`.  \n",
    "\n",
    "---\n",
    "\n",
    "### 7 **Evaluación del Modelo MLP**\n",
    "Una vez entrenado, se calculan las métricas de evaluación:\n",
    "\n",
    "- **Accuracy** (Porcentaje de predicciones correctas).  \n",
    "- **F1-Score** (Balance entre precisión y recall).  \n",
    "- **Precision** (Exactitud de las predicciones).  \n",
    "- **Recall** (Capacidad de detectar correctamente cada clase).  \n",
    "\n",
    "Los resultados se imprimen en la consola para su análisis.  \n",
    "\n",
    "---\n",
    "\n",
    "### 8 **Optimización del Modelo MLP con GridSearch y CrossValidation**\n",
    "\n",
    "Para mejorar el rendimiento del modelo de red neuronal, se implementa **Validación Cruzada (CrossValidation)** con **GridSearch** para optimizar los hiperparámetros más relevantes.  \n",
    "\n",
    "### **Hiperparámetros Optimizados**\n",
    "Se probarán diferentes combinaciones de los siguientes parámetros:  \n",
    "\n",
    "- **Estructura de la red (`layers`)**:\n",
    "  - `[num_features, 32, num_classes]` → Red más simple.  \n",
    "  - `[num_features, 64, 32, num_classes]` → Configuración actual (baseline).  \n",
    "  - `[num_features, 128, 64, 32, num_classes]` → Red más profunda con más capas.  \n",
    "\n",
    "- **Número de iteraciones (`maxIter`)**:\n",
    "  - Se probarán `100` y `200` iteraciones para evaluar la convergencia del modelo.  \n",
    "\n",
    "---\n",
    "\n",
    "### 9 **Guardado y Uso del Modelo**\n",
    "El modelo MLP entrenado se guarda en `models/best_mlp_classification`.  \n",
    "Se puede recargar en el futuro para realizar nuevas predicciones sin necesidad de volver a entrenarlo.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- carat: float (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: float (nullable = true)\n",
      " |-- table: float (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: float (nullable = true)\n",
      " |-- y: float (nullable = true)\n",
      " |-- z: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una copia del DataFrame original para el modelo MLP\n",
    "df_mlp_classification = df_classification.select(\"*\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "df_mlp_classification.show(5)\n",
    "df_mlp_classification.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      cut|label|\n",
      "+---------+-----+\n",
      "|    Ideal|  0.0|\n",
      "|  Premium|  1.0|\n",
      "|     Good|  3.0|\n",
      "|  Premium|  1.0|\n",
      "|     Good|  3.0|\n",
      "|Very Good|  2.0|\n",
      "|Very Good|  2.0|\n",
      "|Very Good|  2.0|\n",
      "|     Fair|  4.0|\n",
      "|Very Good|  2.0|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Clases indexadas: ['Ideal', 'Premium', 'Very Good', 'Good', 'Fair']\n"
     ]
    }
   ],
   "source": [
    "# Crear el indexador para la columna \"cut\"\n",
    "indexer_label_mlp = StringIndexer(inputCol=\"cut\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Aplicar el indexador para transformar \"cut\" en \"label\"\n",
    "indexer_model = indexer_label_mlp.fit(df_mlp_classification)\n",
    "df_mlp_classification = indexer_model.transform(df_mlp_classification)\n",
    "\n",
    "# Mostrar los primeros valores de \"cut\" y su índice \"label\"\n",
    "df_mlp_classification.select(\"cut\", \"label\").show(10)\n",
    "\n",
    "# Verificar las clases asignadas\n",
    "labels_cut = indexer_model.labels\n",
    "print(\"Clases indexadas:\", labels_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+---------------+\n",
      "|color|color_indexed|clarity|clarity_indexed|\n",
      "+-----+-------------+-------+---------------+\n",
      "|    E|          1.0|    SI2|            2.0|\n",
      "|    E|          1.0|    SI1|            0.0|\n",
      "|    E|          1.0|    VS1|            3.0|\n",
      "|    I|          5.0|    VS2|            1.0|\n",
      "|    J|          6.0|    SI2|            2.0|\n",
      "|    J|          6.0|   VVS2|            4.0|\n",
      "|    I|          5.0|   VVS1|            5.0|\n",
      "|    H|          3.0|    SI1|            0.0|\n",
      "|    E|          1.0|    VS2|            1.0|\n",
      "|    H|          3.0|    VS1|            3.0|\n",
      "+-----+-------------+-------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Categorías de color indexadas: [Row(color_indexed=0.0), Row(color_indexed=1.0), Row(color_indexed=2.0), Row(color_indexed=3.0), Row(color_indexed=4.0), Row(color_indexed=5.0), Row(color_indexed=6.0)]\n",
      "Categorías de clarity indexadas: [Row(clarity_indexed=0.0), Row(clarity_indexed=1.0), Row(clarity_indexed=2.0), Row(clarity_indexed=3.0), Row(clarity_indexed=4.0), Row(clarity_indexed=5.0), Row(clarity_indexed=6.0), Row(clarity_indexed=7.0)]\n"
     ]
    }
   ],
   "source": [
    "# Lista de variables categóricas a indexar (sin incluir \"cut\" que ya está indexada)\n",
    "categorical_cols_mlp = [\"color\", \"clarity\"]\n",
    "\n",
    "# Crear indexadores para cada columna categórica\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexers_features_mlp = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + \"_indexed\", handleInvalid=\"keep\") \n",
    "    for c in categorical_cols_mlp\n",
    "]\n",
    "\n",
    "# Aplicar los indexadores uno por uno\n",
    "for indexer in indexers_features_mlp:\n",
    "    model = indexer.fit(df_mlp_classification)\n",
    "    df_mlp_classification = model.transform(df_mlp_classification)\n",
    "\n",
    "# Mostrar los valores transformados\n",
    "df_mlp_classification.select(\"color\", \"color_indexed\", \"clarity\", \"clarity_indexed\").show(10)\n",
    "\n",
    "# Verificar que las clases han sido indexadas correctamente\n",
    "print(\"Categorías de color indexadas:\", df_mlp_classification.select(\"color_indexed\").distinct().orderBy(\"color_indexed\").collect())\n",
    "print(\"Categorías de clarity indexadas:\", df_mlp_classification.select(\"clarity_indexed\").distinct().orderBy(\"clarity_indexed\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------------+---------------+\n",
      "|color_indexed|color_imputed|clarity_indexed|clarity_imputed|\n",
      "+-------------+-------------+---------------+---------------+\n",
      "|          1.0|          1.0|            2.0|            2.0|\n",
      "|          1.0|          1.0|            0.0|            0.0|\n",
      "|          1.0|          1.0|            3.0|            3.0|\n",
      "|          5.0|          5.0|            1.0|            1.0|\n",
      "|          6.0|          6.0|            2.0|            2.0|\n",
      "|          6.0|          6.0|            4.0|            4.0|\n",
      "|          5.0|          5.0|            5.0|            5.0|\n",
      "|          3.0|          3.0|            0.0|            0.0|\n",
      "|          1.0|          1.0|            1.0|            1.0|\n",
      "|          3.0|          3.0|            3.0|            3.0|\n",
      "+-------------+-------------+---------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------------+-----+-------------+\n",
      "|carat|carat_imputed|depth|depth_imputed|\n",
      "+-----+-------------+-----+-------------+\n",
      "| 0.23|         0.23| 61.5|         61.5|\n",
      "| 0.21|         0.21| 59.8|         59.8|\n",
      "| 0.23|         0.23| 56.9|         56.9|\n",
      "| 0.29|         0.29| 62.4|         62.4|\n",
      "| 0.31|         0.31| 63.3|         63.3|\n",
      "| 0.24|         0.24| 62.8|         62.8|\n",
      "| 0.24|         0.24| 62.3|         62.3|\n",
      "| 0.26|         0.26| 61.9|         61.9|\n",
      "| 0.22|         0.22| 65.1|         65.1|\n",
      "| 0.23|         0.23| 59.4|         59.4|\n",
      "+-----+-------------+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos en categóricas indexadas\n",
    "imputer_categorical_mlp = Imputer(\n",
    "    inputCols=[\"color_indexed\", \"clarity_indexed\"],\n",
    "    outputCols=[\"color_imputed\", \"clarity_imputed\"],\n",
    "    strategy=\"mode\"  # Se reemplazan nulos con el valor más frecuente\n",
    ")\n",
    "\n",
    "# Aplicar imputación\n",
    "df_mlp_classification = imputer_categorical_mlp.fit(df_mlp_classification).transform(df_mlp_classification)\n",
    "\n",
    "# Imputar valores nulos en variables numéricas\n",
    "numerical_cols_mlp = [\"carat\", \"depth\", \"table\", \"price\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "imputer_numerical_mlp = Imputer(\n",
    "    inputCols=numerical_cols_mlp,\n",
    "    outputCols=[c + \"_imputed\" for c in numerical_cols_mlp],\n",
    "    strategy=\"median\"  # Se reemplazan nulos con la mediana\n",
    ")\n",
    "\n",
    "# Aplicar imputación\n",
    "df_mlp_classification = imputer_numerical_mlp.fit(df_mlp_classification).transform(df_mlp_classification)\n",
    "\n",
    "# Mostrar los primeros registros después de la imputación\n",
    "df_mlp_classification.select(\"color_indexed\", \"color_imputed\", \"clarity_indexed\", \"clarity_imputed\").show(10)\n",
    "df_mlp_classification.select(\"carat\", \"carat_imputed\", \"depth\", \"depth_imputed\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------------+--------------+\n",
      "|color_imputed|color_onehot |clarity_imputed|clarity_onehot|\n",
      "+-------------+-------------+---------------+--------------+\n",
      "|1.0          |(6,[1],[1.0])|2.0            |(7,[2],[1.0]) |\n",
      "|1.0          |(6,[1],[1.0])|0.0            |(7,[0],[1.0]) |\n",
      "|1.0          |(6,[1],[1.0])|3.0            |(7,[3],[1.0]) |\n",
      "|5.0          |(6,[5],[1.0])|1.0            |(7,[1],[1.0]) |\n",
      "|6.0          |(6,[],[])    |2.0            |(7,[2],[1.0]) |\n",
      "|6.0          |(6,[],[])    |4.0            |(7,[4],[1.0]) |\n",
      "|5.0          |(6,[5],[1.0])|5.0            |(7,[5],[1.0]) |\n",
      "|3.0          |(6,[3],[1.0])|0.0            |(7,[0],[1.0]) |\n",
      "|1.0          |(6,[1],[1.0])|1.0            |(7,[1],[1.0]) |\n",
      "|3.0          |(6,[3],[1.0])|3.0            |(7,[3],[1.0]) |\n",
      "+-------------+-------------+---------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar One-Hot Encoding a las variables categóricas imputadas\n",
    "encoders_onehot_mlp = [\n",
    "    OneHotEncoder(inputCol=\"color_imputed\", outputCol=\"color_onehot\"),\n",
    "    OneHotEncoder(inputCol=\"clarity_imputed\", outputCol=\"clarity_onehot\")\n",
    "]\n",
    "\n",
    "# Aplicar transformación\n",
    "for encoder in encoders_onehot_mlp:\n",
    "    df_mlp_classification = encoder.fit(df_mlp_classification).transform(df_mlp_classification)\n",
    "\n",
    "# Verificar que las columnas codificadas han sido creadas correctamente\n",
    "df_mlp_classification.select(\"color_imputed\", \"color_onehot\", \"clarity_imputed\", \"clarity_onehot\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,2,3,4,5,6,8,15],[0.23000000417232513,61.5,55.0,326.0,3.950000047683716,3.9800000190734863,2.430000066757202,1.0,1.0])              |\n",
      "|(20,[0,1,2,3,4,5,6,8,13],[0.20999999344348907,59.79999923706055,61.0,326.0,3.890000104904175,3.8399999141693115,2.309999942779541,1.0,1.0]) |\n",
      "|(20,[0,1,2,3,4,5,6,8,16],[0.23000000417232513,56.900001525878906,65.0,327.0,4.050000190734863,4.070000171661377,2.309999942779541,1.0,1.0]) |\n",
      "|(20,[0,1,2,3,4,5,6,12,14],[0.28999999165534973,62.400001525878906,58.0,334.0,4.199999809265137,4.230000019073486,2.630000114440918,1.0,1.0])|\n",
      "|(20,[0,1,2,3,4,5,6,15],[0.3100000023841858,63.29999923706055,58.0,335.0,4.340000152587891,4.349999904632568,2.75,1.0])                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensamblar todas las características en una sola columna \"features\"\n",
    "all_features_mlp = [\"carat_imputed\", \"depth_imputed\", \"table_imputed\", \"price_imputed\", \n",
    "                    \"x_imputed\", \"y_imputed\", \"z_imputed\", \"color_onehot\", \"clarity_onehot\"]\n",
    "\n",
    "assembler_all_mlp = VectorAssembler(inputCols=all_features_mlp, outputCol=\"features\")\n",
    "\n",
    "# Aplicar ensamblado\n",
    "df_mlp_classification = assembler_all_mlp.transform(df_mlp_classification)\n",
    "\n",
    "# Mostrar la nueva columna \"features\"\n",
    "df_mlp_classification.select(\"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features_scaled                                                                                                                                                                 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,2,4,5,6,8,15],[0.006237006191921662,0.5138888888888888,0.23076923076923078,0.3677839973801482,0.06757215477023024,0.076415098272242,1.0,1.0])                          |\n",
      "|(20,[0,1,2,4,5,6,8,13],[0.0020789999986709777,0.4666666454739041,0.34615384615384615,0.3621974104101101,0.06519524303377361,0.07264150937737782,1.0,1.0])                       |\n",
      "|(20,[0,1,2,3,4,5,6,8,16],[0.006237006191921662,0.3861111534966363,0.42307692307692313,5.406282099799968E-5,0.37709499786266837,0.06910017090361432,0.07264150937737782,1.0,1.0])|\n",
      "|(20,[0,1,2,3,4,5,6,12,14],[0.018711015477810622,0.5388889312744141,0.2884615384615385,4.3250256798399743E-4,0.3910614430886404,0.07181663683344644,0.08270440809872245,1.0,1.0])|\n",
      "|(20,[0,1,2,3,4,5,6,15],[0.022869021671061307,0.5638888676961262,0.2884615384615385,4.865653889819971E-4,0.4040968570836425,0.07385398628082052,0.08647798949614685,1.0])        |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizar la columna \"features\"\n",
    "scaler_mlp = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Aplicar escalado\n",
    "scaler_model = scaler_mlp.fit(df_mlp_classification)\n",
    "df_mlp_classification = scaler_model.transform(df_mlp_classification)\n",
    "\n",
    "# Mostrar la columna \"features_scaled\"\n",
    "df_mlp_classification.select(\"features_scaled\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características de entrada: 20\n",
      "Número de clases de salida: 5\n",
      "Estructura de la red neuronal (capas): [20, 64, 32, 5]\n"
     ]
    }
   ],
   "source": [
    "# Determinar el número de características y clases\n",
    "num_features = df_mlp_classification.select(\"features_scaled\").first()[0].size\n",
    "num_classes = df_mlp_classification.select(\"label\").distinct().count()\n",
    "\n",
    "# Definir la estructura de la red neuronal\n",
    "layers = [num_features, 64, 32, num_classes]\n",
    "\n",
    "# Imprimir detalles de la red neuronal\n",
    "print(f\"Número de características de entrada: {num_features}\")\n",
    "print(f\"Número de clases de salida: {num_classes}\")\n",
    "print(f\"Estructura de la red neuronal (capas): {layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       2.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       2.0|\n",
      "|  3.0|       4.0|\n",
      "|  3.0|       3.0|\n",
      "|  3.0|       2.0|\n",
      "|  3.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo MLP\n",
    "mlp_classifier = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"features_scaled\",  # Usamos la versión escalada de las features\n",
    "    labelCol=\"label\",\n",
    "    layers=layers,\n",
    "    seed=42,\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "# Crear pipeline con todas las etapas\n",
    "pipeline_mlp = Pipeline(stages=[mlp_classifier])\n",
    "\n",
    "# Dividir datos en entrenamiento (80%) y prueba (20%)\n",
    "df_train_mlp, df_test_mlp = df_mlp_classification.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "pipeline_model_mlp = pipeline_mlp.fit(df_train_mlp)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "df_pred_mlp = pipeline_model_mlp.transform(df_test_mlp)\n",
    "\n",
    "# Mostrar algunas predicciones\n",
    "df_pred_mlp.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Modelo MLP**\n",
      "Accuracy: 0.5653\n",
      "F1-Score: 0.5060\n",
      "Precision: 0.5103\n",
      "Recall: 0.5653\n"
     ]
    }
   ],
   "source": [
    "# Definir evaluadores\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Evaluar el modelo MLP\n",
    "accuracy_mlp = evaluator_accuracy.evaluate(df_pred_mlp)\n",
    "f1_mlp = evaluator_f1.evaluate(df_pred_mlp)\n",
    "precision_mlp = evaluator_precision.evaluate(df_pred_mlp)\n",
    "recall_mlp = evaluator_recall.evaluate(df_pred_mlp)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n**Evaluación del Modelo MLP**\")\n",
    "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
    "print(f\"F1-Score: {f1_mlp:.4f}\")\n",
    "print(f\"Precision: {precision_mlp:.4f}\")\n",
    "print(f\"Recall: {recall_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Evaluación del Mejor Modelo MLP (GridSearch + CrossValidation)**\n",
      "Accuracy: 0.6713\n",
      "F1-Score: 0.6415\n",
      "Precision: 0.6457\n",
      "Recall: 0.6713\n"
     ]
    }
   ],
   "source": [
    "# Definir la cuadrícula de hiperparámetros para MLP\n",
    "paramGrid_mlp = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(mlp_classifier.layers, [\n",
    "        [num_features, 32, num_classes],      # Estructura más simple\n",
    "        [num_features, 64, 32, num_classes],  # Estructura actual (baseline)\n",
    "        [num_features, 128, 64, 32, num_classes]  # Red más profunda\n",
    "    ])\n",
    "    .addGrid(mlp_classifier.maxIter, [100, 200])  # Número de iteraciones\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Configurar CrossValidator\n",
    "crossval_mlp = CrossValidator(\n",
    "    estimator=pipeline_mlp,               # Pipeline de MLP\n",
    "    estimatorParamMaps=paramGrid_mlp,      # Hiperparámetros\n",
    "    evaluator=evaluator_f1,                # Evaluar con F1-Score\n",
    "    numFolds=3,                            # 3-Fold Cross Validation\n",
    "    parallelism=4,                          # Procesamiento en paralelo\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo optimizado\n",
    "cv_model_mlp = crossval_mlp.fit(df_train_mlp)\n",
    "\n",
    "# Hacer predicciones con el mejor modelo encontrado\n",
    "df_pred_cv_mlp = cv_model_mlp.transform(df_test_mlp)\n",
    "\n",
    "# Evaluar el modelo optimizado\n",
    "accuracy_cv_mlp = evaluator_accuracy.evaluate(df_pred_cv_mlp)\n",
    "f1_cv_mlp = evaluator_f1.evaluate(df_pred_cv_mlp)\n",
    "precision_cv_mlp = evaluator_precision.evaluate(df_pred_cv_mlp)\n",
    "recall_cv_mlp = evaluator_recall.evaluate(df_pred_cv_mlp)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\n**Evaluación del Mejor Modelo MLP (GridSearch + CrossValidation)**\")\n",
    "print(f\"Accuracy: {accuracy_cv_mlp:.4f}\")\n",
    "print(f\"F1-Score: {f1_cv_mlp:.4f}\")\n",
    "print(f\"Precision: {precision_cv_mlp:.4f}\")\n",
    "print(f\"Recall: {recall_cv_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor modelo MLP optimizado guardado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el mejor modelo optimizado\n",
    "cv_model_mlp.bestModel.write().overwrite().save(\"models/best_mlp_classification_optimized\")\n",
    "\n",
    "print(\"\\nMejor modelo MLP optimizado guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análisis Final del Modelo MLP Optimizado**  \n",
    "\n",
    "Después de aplicar **GridSearch + CrossValidation**, se obtuvo el mejor modelo de red neuronal con los siguientes resultados:  \n",
    "\n",
    "### **Resultados de Evaluación**  \n",
    "| Métrica    | Valor  |\n",
    "|------------|--------|\n",
    "| **Accuracy**  | `0.6713` |\n",
    "| **F1-Score**  | `0.6415` |\n",
    "| **Precision** | `0.6457` |\n",
    "| **Recall**    | `0.6713` |\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretación de los Resultados**  \n",
    "\n",
    "1️ **Mejora en el Rendimiento**  \n",
    "- Comparado con el modelo base, que tenía un **Accuracy de 0.5653**, la versión optimizada logra un **+10% de mejora en precisión general**.  \n",
    "- El **F1-Score** también mejora significativamente, indicando un mejor balance entre **precisión** y **recall**.  \n",
    "\n",
    "2️ **Generalización y Robustez**  \n",
    "- Gracias a la **validación cruzada**, el modelo evita **overfitting** y generaliza mejor a nuevos datos.  \n",
    "- La precisión aumentada sugiere que el modelo **distingue mejor las categorías de `cut`**, aunque aún hay margen de mejora.  \n",
    "\n",
    "3️ **Posibles Mejoras Futuras**  \n",
    "- **Más capas y neuronas**: Explorar redes más profundas con estructuras como `[num_features, 256, 128, 64, 32, num_classes]`.  \n",
    "- **Más datos de entrenamiento**: Aumentar la cantidad de datos puede mejorar la capacidad de aprendizaje del modelo.  \n",
    "- **Hiperparámetros adicionales**: Ajustar el **learning rate**, la **función de activación**, y el **batch size**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusión**  \n",
    "**El modelo optimizado con MLP y GridSearch mejora notablemente el rendimiento respecto a la versión inicial.**  \n",
    "**Se lograron predicciones más precisas y balanceadas entre clases.**  \n",
    "**Aún hay oportunidades de optimización explorando redes más profundas y ajustes más finos en los hiperparámetros.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Guardado del Mejor Modelo**  \n",
    "El modelo optimizado ha sido almacenado en `models/best_mlp_classification` para su uso en futuras predicciones sin necesidad de volver a entrenarlo.  \n",
    "\n",
    "```python\n",
    "cv_model_mlp.bestModel.write().overwrite().save(\"models/best_mlp_classification\")\n",
    "print(\"\\nMejor modelo MLP guardado con éxito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
