{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|\n",
      "| Adelie|Torgersen|          40.3|         18.0|            195.0|     3250.0|Female|\n",
      "| Adelie|Torgersen|           NaN|          NaN|              NaN|        NaN|   NaN|\n",
      "| Adelie|Torgersen|          36.7|         19.3|            193.0|     3450.0|Female|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('clasificacion_penguins').getOrCreate()\n",
    "df = spark.createDataFrame(sns.load_dataset('penguins'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos predecir species por tanto elimino filas donde species sea nan\n",
    "df = df.dropna(subset=['species'])\n",
    "# si estuviera en dataframe de pandas: \n",
    "# df['island'] = df['island'].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
      "['island', 'sex']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import NumericType, StringType\n",
    "\n",
    "numeric_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "# Filtramos species porque species es la variable a predecir y ya hemos asegurado que no tiene nan\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType) and field.name != 'species']\n",
    "\n",
    "print(numeric_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|\n",
      "| Adelie|Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    strategy='median',\n",
    "    inputCols=numeric_cols,\n",
    "    outputCols=[col + '_imputed' for col in numeric_cols]\n",
    ")\n",
    "imputer_model = imputer.fit(df_train) # fit solo sobre train para evitar fuga de datos data leakage\n",
    "df_train = imputer_model.transform(df_train)\n",
    "df_test = imputer_model.transform(df_test)\n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- island: string (nullable = true)\n",
      " |-- bill_length_mm: double (nullable = true)\n",
      " |-- bill_depth_mm: double (nullable = true)\n",
      " |-- flipper_length_mm: double (nullable = true)\n",
      " |-- body_mass_g: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bill_length_mm_imputed: double (nullable = true)\n",
      " |-- bill_depth_mm_imputed: double (nullable = true)\n",
      " |-- flipper_length_mm_imputed: double (nullable = true)\n",
      " |-- body_mass_g_imputed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 1: rellenar con un valor fijo\n",
    "# al inferir el schema automáticamente nos está diciendo que la columna sex NO es nullable y no tiene nan, por lo que en realidad\n",
    "# lo que está pasando es que los NaN los tiene como palabras 'NaN' texto, por tanto no sirve el fill y usamos replace:\n",
    "\n",
    "# df_train = df_train.na.fill('other', subset=categorical_cols)\n",
    "# df_test = df_test.na.fill('other', subset=categorical_cols)\n",
    "\n",
    "# df_train = df_train.fillna('other', subset=categorical_cols)\n",
    "# df_test = df_test.fillna('other', subset=categorical_cols)\n",
    "\n",
    "# df_train = df_train.replace('NaN', 'other', subset=categorical_cols)\n",
    "# df_test = df_test.replace('NaN', 'other', subset=categorical_cols)\n",
    "\n",
    "# df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción 2: usar Imputer\n",
    "# No se puede, IllegalArgumentException, requiere numéricas.\n",
    "# Se haría si hemos hecho primero un StringIndexer para convertir a numéricas a índices\n",
    "# imputer = Imputer(\n",
    "#     strategy='mode',\n",
    "#     inputCols=categorical_cols,\n",
    "#     outputCols=[col + '_imputed' for col in categorical_cols]\n",
    "# )\n",
    "# imputer_model = imputer.fit(df_train) # fit solo sobre train para evitar fuga de datos data leakage\n",
    "# df_train = imputer_model.transform(df_train)\n",
    "# df_test = imputer_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   island|count|\n",
      "+---------+-----+\n",
      "|   Biscoe|  168|\n",
      "|    Dream|  124|\n",
      "|Torgersen|   52|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ver value_counts para ver valors más frecuentes\n",
    "from pyspark.sql.functions import col\n",
    "df.groupBy('island').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|  Male|  168|\n",
      "|Female|  165|\n",
      "|   NaN|   11|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('sex').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|\n",
      "| Adelie|Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|\n",
      "| Adelie|Biscoe|          37.9|         18.6|            172.0|     3150.0|Female|                  37.9|                 18.6|                    172.0|             3150.0|\n",
      "| Adelie|Biscoe|          38.2|         18.1|            185.0|     3950.0|  Male|                  38.2|                 18.1|                    185.0|             3950.0|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opción 3: rellenar con la moda\n",
    "island_mode = df.groupBy('island').count().orderBy(col('count').desc()).first()['island']\n",
    "sex_mode = df.groupBy('sex').count().orderBy(col('count').desc()).first()['sex']\n",
    "\n",
    "df_train = df_train.replace('NaN', island_mode, subset=['island'])\n",
    "df_test = df_test.replace('NaN', island_mode, subset=['island'])\n",
    "\n",
    "df_train = df_train.replace('NaN', sex_mode, subset=['sex'])\n",
    "df_test = df_test.replace('NaN', sex_mode, subset=['sex'])\n",
    "\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StringIndexer + OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|  0.0|           0.0|        1.0|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|  0.0|           0.0|        1.0|\n",
      "| Adelie|Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexed_label = StringIndexer(inputCol='species', outputCol='label')\n",
    "indexed_model = indexed_label.fit(df_train)\n",
    "df_train = indexed_model.transform(df_train)\n",
    "df_test = indexed_model.transform(df_test)\n",
    "\n",
    "for categorical_col in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=categorical_col, outputCol=categorical_col + '_indexed')\n",
    "    model = indexer.fit(df_train)\n",
    "    df_train = model.transform(df_train)\n",
    "    df_test = model.transform(df_test)\n",
    "    \n",
    "df_train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|   sex_onehot|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|\n",
      "| Adelie|Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|\n",
      "| Adelie|Biscoe|          37.9|         18.6|            172.0|     3150.0|Female|                  37.9|                 18.6|                    172.0|             3150.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|\n",
      "| Adelie|Biscoe|          38.2|         18.1|            185.0|     3950.0|  Male|                  38.2|                 18.1|                    185.0|             3950.0|  0.0|           0.0|        0.0|(2,[0],[1.0])|(1,[0],[1.0])|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[col + '_indexed' for col in categorical_cols],\n",
    "    outputCols= [col + '_onehot' for col in categorical_cols]\n",
    ")\n",
    "\n",
    "model = encoder.fit(df_train)\n",
    "df_train = model.transform(df_train)\n",
    "df_test = model.transform(df_test)\n",
    "\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['island_onehot',\n",
       " 'sex_onehot',\n",
       " 'bill_length_mm_imputed',\n",
       " 'bill_depth_mm_imputed',\n",
       " 'flipper_length_mm_imputed',\n",
       " 'body_mass_g_imputed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = [col + '_onehot' for col in categorical_cols]\n",
    "imputed = [col + '_imputed' for col in numeric_cols]\n",
    "onehot + imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+----------+--------------------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|sex_onehot|            features|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+----------+--------------------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])| (1,[],[])|[1.0,0.0,0.0,35.3...|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])| (1,[],[])|[1.0,0.0,0.0,35.9...|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=onehot + imputed,\n",
    "    outputCol='features'\n",
    ")\n",
    "df_train = assembler.transform(df_train)\n",
    "df_test = assembler.transform(df_test)\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "|species|island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|bill_length_mm_imputed|bill_depth_mm_imputed|flipper_length_mm_imputed|body_mass_g_imputed|label|island_indexed|sex_indexed|island_onehot|   sex_onehot|            features|     scaled_festures|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "| Adelie|Biscoe|          35.3|         18.9|            187.0|     3800.0|Female|                  35.3|                 18.9|                    187.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,35.3...|[1.07446271288578...|\n",
      "| Adelie|Biscoe|          35.9|         19.2|            189.0|     3800.0|Female|                  35.9|                 19.2|                    189.0|             3800.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,35.9...|[1.07446271288578...|\n",
      "| Adelie|Biscoe|          37.8|         18.3|            174.0|     3400.0|Female|                  37.8|                 18.3|                    174.0|             3400.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,37.8...|[1.07446271288578...|\n",
      "| Adelie|Biscoe|          37.9|         18.6|            172.0|     3150.0|Female|                  37.9|                 18.6|                    172.0|             3150.0|  0.0|           0.0|        1.0|(2,[0],[1.0])|    (1,[],[])|[1.0,0.0,0.0,37.9...|[1.07446271288578...|\n",
      "| Adelie|Biscoe|          38.2|         18.1|            185.0|     3950.0|  Male|                  38.2|                 18.1|                    185.0|             3950.0|  0.0|           0.0|        0.0|(2,[0],[1.0])|(1,[0],[1.0])|[1.0,0.0,1.0,38.2...|[1.07446271288578...|\n",
      "+-------+------+--------------+-------------+-----------------+-----------+------+----------------------+---------------------+-------------------------+-------------------+-----+--------------+-----------+-------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='scaled_festures',\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "model = scaler.fit(df_train)\n",
    "df_train = model.transform(df_train)\n",
    "df_test = model.transform(df_test)\n",
    "\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, \n",
    "    DecisionTreeClassifier, \n",
    "    RandomForestClassifier, \n",
    "    GBTClassifier, \n",
    "    MultilayerPerceptronClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "f1 1.0\n",
      "precision 1.0\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "f1 1.0\n",
      "precision 1.0\n",
      "recall 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 59156)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='scaled_festures')\n",
    "model = lr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
