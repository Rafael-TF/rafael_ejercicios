{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|\n",
      "| Adelie|Torgersen|          40.3|         18.0|            195.0|     3250.0|Female|\n",
      "| Adelie|Torgersen|          36.7|         19.3|            193.0|     3450.0|Female|\n",
      "| Adelie|Torgersen|          39.3|         20.6|            190.0|     3650.0|  Male|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('clasificacion_penguins').getOrCreate()\n",
    "df = spark.createDataFrame(sns.load_dataset('penguins').dropna()) # Le quitamos los nulos\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding y Assembler\n",
    "\n",
    "Para poder usar las columnas categóricas tenemos que codificarlas, como ocurría en scikit learn.\n",
    "\n",
    "La diferencia es que para poder usar OneHotEncoder primero tenemos que usar StringIndexer, porque el OneHotEncoder de spark requiere números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|species_indexed|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|            0.0|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|            0.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "\n",
    "# 1. StringIndexers\n",
    "indexer_species = StringIndexer(inputCol='species', outputCol='species_indexed')\n",
    "df = indexer_species.fit(df).transform(df)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|species_indexed|label|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|            0.0|  2.0|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|            0.0|  2.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# columna a predecir: island\n",
    "indexer_islands = StringIndexer(inputCol='island', outputCol='label')\n",
    "df = indexer_islands.fit(df).transform(df)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|species_indexed|label|sex_indexed|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|            0.0|  2.0|        0.0|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|            0.0|  2.0|        1.0|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# columna género\n",
    "indexer_sex = StringIndexer(inputCol='sex', outputCol='sex_indexed')\n",
    "df = indexer_sex.fit(df).transform(df)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|species_indexed|label|sex_indexed|species_onehot|   sex_onehot|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|            0.0|  2.0|        0.0| (2,[0],[1.0])|(1,[0],[1.0])|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|            0.0|  2.0|        1.0| (2,[0],[1.0])|    (1,[],[])|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. OneHotEncoder sobre las categóricas de la entrada que usaremos en features: species_indexed, sex_indexed\n",
    "# Es obligatorio haber hecho StringIndexer para tener las categóricas como índices numéricos, si no dará error IllegalArgumentException\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=['species_indexed', 'sex_indexed'],\n",
    "    outputCols=['species_onehot', 'sex_onehot']\n",
    ")\n",
    "df = encoder.fit(df).transform(df)\n",
    "df.show(2) # Genera nuevas columnas cada una de ellas es un SparseVector, que ahorra espacio en memoria en comparación con vector denso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+--------------------+\n",
      "|species|   island|bill_length_mm|bill_depth_mm|flipper_length_mm|body_mass_g|   sex|species_indexed|label|sex_indexed|species_onehot|   sex_onehot|            features|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+--------------------+\n",
      "| Adelie|Torgersen|          39.1|         18.7|            181.0|     3750.0|  Male|            0.0|  2.0|        0.0| (2,[0],[1.0])|(1,[0],[1.0])|[39.1,18.7,181.0,...|\n",
      "| Adelie|Torgersen|          39.5|         17.4|            186.0|     3800.0|Female|            0.0|  2.0|        1.0| (2,[0],[1.0])|    (1,[],[])|[39.5,17.4,186.0,...|\n",
      "+-------+---------+--------------+-------------+-----------------+-----------+------+---------------+-----+-----------+--------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'species_onehot', 'sex_onehot'],\n",
    "    outputCol='features'\n",
    ")\n",
    "df = assembler.transform(df)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[39.1,18.7,181.0,...|  2.0|\n",
      "|[39.5,17.4,186.0,...|  2.0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quedarnos con features y label para poder hacer modelado\n",
    "df_to_predict = df.select('features', 'label')\n",
    "df_to_predict.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_to_predict.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, \n",
    "    DecisionTreeClassifier, \n",
    "    RandomForestClassifier, \n",
    "    GBTClassifier, \n",
    "    MultilayerPerceptronClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[35.9,19.2,189.0,...|  0.0|[-0.3957289061333...|[0.21635034123350...|       2.0|\n",
      "|[37.8,18.3,174.0,...|  0.0|[0.83150611497343...|[0.62530484025805...|       0.0|\n",
      "|[38.6,21.2,191.0,...|  2.0|[-0.1358787517031...|[0.28962512108041...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "df_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "# No tiene AUC para multiclass: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator.metricName\n",
    "# evaluator_auc = MulticlassClassificationEvaluator(metricName='areaUnderROC')\n",
    "# Alternativa, sacar manualmente TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6612903225806451\n",
      "f1 0.6618494892809561\n",
      "precision 0.6808542413381122\n",
      "recall 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.532258064516129\n",
      "f1 0.3697792869269949\n",
      "precision 0.28329864724245574\n",
      "recall 0.532258064516129\n"
     ]
    }
   ],
   "source": [
    "# Red neuronal de clasificación multiclase\n",
    "\n",
    "num_features = df_train.first()['features'].size\n",
    "num_labels = df.select('label').distinct().count()\n",
    "# layers=[capa input, capas ocultas..., capa output]\n",
    "mlp = MultilayerPerceptronClassifier(layers=[num_features, 32, 32, num_labels], seed=42, maxIter=10)\n",
    "model = mlp.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html\n",
    "# Multiclass labels are not currently supported.\n",
    "# De momento solo sirve para clasificación binaria, si tenemos más de 2 labels lanza error\n",
    "# gpt = GBTClassifier(seed=42)\n",
    "# model = gpt.fit(df_train)\n",
    "# df_pred = model.transform(df_test)\n",
    "# print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "# print('f1', evaluator_f1.evaluate(df_pred))\n",
    "# print('precision', evaluator_precision.evaluate(df_pred))\n",
    "# print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6129032258064516\n",
      "f1 0.6093997421164548\n",
      "precision 0.6165703040007823\n",
      "recall 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "# posible solucion: \n",
    "# convertir un problema multiclase en varios problemas binarios\n",
    "# utilizando OneVsRest, que entrena múltiples modelos GBTClassifier, \n",
    "# uno para cada clase contra el resto\n",
    "from pyspark.ml.classification import OneVsRest\n",
    "\n",
    "gbt = GBTClassifier()\n",
    "\n",
    "ovr = OneVsRest(classifier=gbt)\n",
    "model = ovr.fit(df_train)\n",
    "df_pred = model.transform(df_test)\n",
    "\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
